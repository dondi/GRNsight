# Expression Database

All files pertaining the expression database live within this directory.

## The basics

### Scripts

All scripts live within the subdirectory `scripts`, located in the top-level of the network database directory.

Any source files required to run the scripts live within the subdirectory `source-files`, located in the top-level of the network database directory. As source files may be large, **you must create this directory yourself and add any source files you need to use there**.

All generated results of the scripts live in the subdirectory `script-results`, located in the top-level of the network database directory. Currently, all scripts that generate code create the directory if it does not currently exist. When adding a new script that generates resulting code, best practice is to create the script-results directory and any subdirectories if it does not exist, in order to prevent errors and snafus for recently cloned repositories.

Within the scripts directory, there are the following files:

- `preprocessing.py`
- `loader.py`

#### Data Preprocessor(s)

_Note: Data Preprocessing is always specific to each dataset that you obtain. `preprocessing.py` is capable of preprocessing the specific Expression data files located in `source-files/Expression 2020`. Because these files are too large to be stored on github, access the direct source files on **[BOX](https://lmu.app.box.com/folder/104464569159?s=4s6yw8009fmc9pq8zn17uu4iyitdskm2)** and move them into this directory. If more data sources are to be added in the database, create a new directory in source-files for it, note it in this `README.md` file and create a new preprocessing script for that data source (if required). Please document the changes in this section so that future developers may use your work to recreate the database if ever required._

The script (`preprocessing.py`) is used to preprocess the data in `source-files/Expression 2020`. It parses through each file to construct the processed loader files, so that they are ready to load using `loader.py`.

The script (`preprocessing.py`) is capable of preprocessing:

    - Expression Data
    - Expression Metadata
    - Genes
    - References
    - Production Rates
    - Degradation Rates
    - (and any future datasets added to the script)

- All processed output files are saved under:
    ```
    script-results/processed-loader-files
    ```

**Usage**:

The preprocessing script supports command-line flags to allow selective preprocessing or full preprocessing.

1. Process everything (default behavior)

If no arguments are specificed:

```
python3 preprocessing.py
```

Or explicitly:

```
python3 preprocessing.py --all --source-folder "Expression 2020"
```

This runs every preprocessing step and regenerates all processed files.

> Notes: The default source data directory is `Expression 2020`, located under `source-files/`.
> If you want to preprocess a different dataset (for example, updated files or a new version), use the `--source-folder` flag to point to the appropriate directory `source-files/<source-folder>/`. Make sure that directory contains all required input CSV files.

2. Process only specific components

You can process individual sections using falgs:

| Option            | Description                                               |
| ----------------- | --------------------------------------------------------- |
| `--expr`          | Process expression data table                             |
| `--meta`          | Process metadata / GEO / PubMed mappings                  |
| `--genes`         | Generate gene list                                        |
| `--refs`          | Generate references file                                  |
| `--prod`          | Process production-rate data                              |
| `--deg`           | Process degradation-rate data                             |
| `--source-folder` | Folder that stores all the files need to be preprocessing |

#### Database Loader

This script (`loader.py`) is to be used to load your preprocessed expression data into the database.

This program generates direct SQL statements from the source files generated by the data preprocessor in order to populate a relational database with those filesâ€™ data

**Usage**:

Similar to `preprocessing.py`, the loading script supports command-line flags to allow selective loading or full loading.

1. Load everything (default behavior)

If no arguments are specificed:

```
python3 loader.py | psql postgresql://localhost/postgres
```

Or explicitly:

```
python3 loader.py --all | psql postgresql://localhost/postgres
```

This runs every loading step and poplulate all data into database.

2. Load only specific components

You can load individual sections using falgs:

| Option    | Description                           |
| --------- | ------------------------------------- |
| `--expr`  | Load expression data table            |
| `--meta`  | Load metadata / GEO / PubMed mappings |
| `--genes` | Generate gene list                    |
| `--refs`  | Generate references file              |
| `--prod`  | Load production-rate data             |
| `--deg`   | Load degradation-rate data            |

Example of loading data into database for production rates and degradation rates:

```
python3 loader.py --prod --deg | psql postgresql://localhost/postgres
```
